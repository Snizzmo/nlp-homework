{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4df91e8",
   "metadata": {},
   "source": [
    "This notebook goes takes the federalist papers and try to create a machine learning algorithm that can predict the author. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a29ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read in the csv file using pandas.\n",
    "# Convert the author column to categorical data.\n",
    "# Display the first few rows.\n",
    "# Display the counts by author.\n",
    "\n",
    "import pandas as pd # Load the Pandas libraries with alias 'pd'\n",
    "df = pd.read_csv(\"federalist.csv\")\n",
    "df['author'] = pd.Categorical(df.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c15c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     author                                               text\n",
      "0  HAMILTON  FEDERALIST. No. 1 General Introduction For the...\n",
      "1       JAY  FEDERALIST No. 2 Concerning Dangers from Forei...\n",
      "2       JAY  FEDERALIST No. 3 The Same Subject Continued (C...\n",
      "3       JAY  FEDERALIST No. 4 The Same Subject Continued (C...\n",
      "4       JAY  FEDERALIST No. 5 The Same Subject Continued (C...\n",
      "\n",
      "\n",
      "HAMILTON                49\n",
      "MADISON                 15\n",
      "HAMILTON OR MADISON     11\n",
      "JAY                      5\n",
      "HAMILTON AND MADISON     3\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preview the first 5 lines of the loaded data\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "print(df.author.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44e614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Divide into train and test, with 80% in train. Use random state 1234.\n",
    "# Display the shape of train and test.\n",
    "\n",
    "# divide into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.text, df.author, test_size=0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a028250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66,) (17,) (66,) (17,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of train and test.\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd5dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test sizes (shapes):  (66,) (17,)\n",
      "peek the data:\n",
      " [[0.         0.         0.02956872 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.02275824 0.         0.        ]] \n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.02314673 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cfran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 3. Process the text by removing stop words and performing tf-idf vectorization\n",
    "# Output the training set shape and the test set shape.\n",
    "\n",
    "# removing stop words and performing tf-idf vectorization\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopwords = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "# vectorize\n",
    "X_train_fit = vectorizer.fit_transform(X_train) # returns document term matrix\n",
    "X_test_fit = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Train and test sizes (shapes): \", X_train.shape, X_test.shape)\n",
    "print(\"peek the data:\\n\", X_train_fit.toarray(), '\\n\\n', X_test_fit.toarray())\n",
    "# print(\"peek the data:\\n\", X_train,'\\n\\n', X_test)\n",
    "# print(\"peek the labels:\\n\", y_train,'\\n\\n', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e8e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "# 4. Bernoulli Naïve Bayes model. What is your accuracy on the test set?\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_fit, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# evaluate on the test data\n",
    "# make predictions on the test data\n",
    "pred = naive_bayes.predict(X_test_fit)\n",
    "\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667753de",
   "metadata": {},
   "source": [
    "This accuracy is very low, at just below 60 percent. Let's see if the problem is the vectorization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae1b419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "# 5. Redo the vectorization with max_features option set to use only the 1000 most frequent\n",
    "# In addition to the words, add bigrams as a feature.\n",
    "# Try Naïve Bayes again on the new train/test vectors and compare your results.\n",
    "\n",
    "# new vectorization\n",
    "vectorizer2 = TfidfVectorizer(stop_words=stopwords, max_features=1000, ngram_range=(1, 2))\n",
    "X_train_fit2 = vectorizer2.fit_transform(X_train) # returns document term matrix\n",
    "X_test_fit2 = vectorizer2.transform(X_test)\n",
    "\n",
    "naive_bayes.fit(X_train_fit2, y_train)\n",
    "pred = naive_bayes.predict(X_test_fit2)\n",
    "\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d275ea38",
   "metadata": {},
   "source": [
    "It looks like the acciracy did not change - the vectorization did not change much about the final accuracy. Let's now look at a different algorithm: logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a7e415",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score without params:\t 0.5882352941176471\n",
      "accuracy score using params:\t 0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "# 6. Try logistic regression. Adjust at least one parameter in the LogisticRegression() mode\n",
    "# to see if you can improve results over having no parameters.\n",
    "# What are your results?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_fit2, y_train)\n",
    "pred = classifier.predict(X_test_fit2)\n",
    "print('accuracy score without params:\\t', accuracy_score(y_test, pred))\n",
    "\n",
    "# Change parameters \n",
    "classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', class_weight='balanced')\n",
    "classifier.fit(X_train_fit2, y_train)\n",
    "pred = classifier.predict(X_test_fit2)\n",
    "print('accuracy score using params:\\t', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e15a77",
   "metadata": {},
   "source": [
    "The accuracy is much improved with a logistic regression with a parameter! However, we can do better. Is there a neural network that can outperform this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa63db57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15, 2 accuracy:\t 0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "# 7. Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15, 2), random_state=1234)\n",
    "classifier.fit(X_train_fit2, y_train)\n",
    "\n",
    "pred = classifier.predict(X_test_fit2)\n",
    "# start with straightforward design\n",
    "print('15, 2 accuracy:\\t', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc508310",
   "metadata": {},
   "source": [
    "The accuracy of this most basic network is not great; how about we adjust the architecture of the network and see if changing the number of layers and nodes per layer helps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9fc5f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0.8235294117647058)\n",
      "((21, 7), 0.8823529411764706)\n"
     ]
    }
   ],
   "source": [
    "# try other topologies, first 1 layer\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "one_layers = []\n",
    "for i in range(1, 66):\n",
    "    classifier = MLPClassifier(solver='lbfgs', max_iter=500, alpha=1e-5, hidden_layer_sizes=(i), random_state=1234)\n",
    "    classifier.fit(X_train_fit2, y_train)\n",
    "    pred = classifier.predict(X_test_fit2)\n",
    "    one_layers.append((i, accuracy_score(y_test, pred)))\n",
    "    #print(i, 'accuracy:\\t', accuracy_score(y_test, pred))\n",
    "print(max(one_layers, key=lambda x: x[1]))\n",
    "\n",
    "# then 2 layers\n",
    "two_layers = []\n",
    "pairs = []\n",
    "for x in range(1, 66):\n",
    "    for y in range(1,10): \n",
    "        pairs.append((x, y))\n",
    "\n",
    "for i in pairs:\n",
    "    classifier = MLPClassifier(solver='lbfgs', max_iter=500, alpha=1e-5, hidden_layer_sizes=(i), random_state=1234)\n",
    "    classifier.fit(X_train_fit2, y_train)\n",
    "    pred = classifier.predict(X_test_fit2)\n",
    "    two_layers.append((i, accuracy_score(y_test, pred)))\n",
    "    #print(i, 'accuracy:\\t', accuracy_score(y_test, pred))\n",
    "print(max(two_layers, key=lambda x: x[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ed7b9",
   "metadata": {},
   "source": [
    "The best neural network here is 2 layers with 21 nodes in the first layer and 7 in the second. \n",
    "\n",
    "This is the best accuracy we've had on any of the tests, thus it would be my choice moving forward. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
